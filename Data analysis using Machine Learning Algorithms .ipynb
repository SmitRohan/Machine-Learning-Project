{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2019-02-06 13:59:07--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/Cust_Segmentation.csv\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.193\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.193|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 34276 (33K) [text/csv]\nSaving to: \u2018Cust_Segmentation.csv\u2019\n\n100%[======================================>] 34,276      --.-K/s   in 0.002s  \n\n2019-02-06 13:59:07 (15.2 MB/s) - \u2018Cust_Segmentation.csv\u2019 saved [34276/34276]\n\n"
                }
            ], 
            "source": "!wget -O Cust_Segmentation.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/Cust_Segmentation.csv"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import pandas as pd"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "Data=pd.read_csv(\"Cust_Segmentation.csv\")"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 6, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer Id</th>\n      <th>Age</th>\n      <th>Edu</th>\n      <th>Years Employed</th>\n      <th>Income</th>\n      <th>Card Debt</th>\n      <th>Other Debt</th>\n      <th>Defaulted</th>\n      <th>Address</th>\n      <th>DebtIncomeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>41</td>\n      <td>2</td>\n      <td>6</td>\n      <td>19</td>\n      <td>0.124</td>\n      <td>1.073</td>\n      <td>0.0</td>\n      <td>NBA001</td>\n      <td>6.3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>47</td>\n      <td>1</td>\n      <td>26</td>\n      <td>100</td>\n      <td>4.582</td>\n      <td>8.218</td>\n      <td>0.0</td>\n      <td>NBA021</td>\n      <td>12.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>33</td>\n      <td>2</td>\n      <td>10</td>\n      <td>57</td>\n      <td>6.111</td>\n      <td>5.802</td>\n      <td>1.0</td>\n      <td>NBA013</td>\n      <td>20.9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>29</td>\n      <td>2</td>\n      <td>4</td>\n      <td>19</td>\n      <td>0.681</td>\n      <td>0.516</td>\n      <td>0.0</td>\n      <td>NBA009</td>\n      <td>6.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>47</td>\n      <td>1</td>\n      <td>31</td>\n      <td>253</td>\n      <td>9.308</td>\n      <td>8.908</td>\n      <td>0.0</td>\n      <td>NBA008</td>\n      <td>7.2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>40</td>\n      <td>1</td>\n      <td>23</td>\n      <td>81</td>\n      <td>0.998</td>\n      <td>7.831</td>\n      <td>NaN</td>\n      <td>NBA016</td>\n      <td>10.9</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>38</td>\n      <td>2</td>\n      <td>4</td>\n      <td>56</td>\n      <td>0.442</td>\n      <td>0.454</td>\n      <td>0.0</td>\n      <td>NBA013</td>\n      <td>1.6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>42</td>\n      <td>3</td>\n      <td>0</td>\n      <td>64</td>\n      <td>0.279</td>\n      <td>3.945</td>\n      <td>0.0</td>\n      <td>NBA009</td>\n      <td>6.6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>26</td>\n      <td>1</td>\n      <td>5</td>\n      <td>18</td>\n      <td>0.575</td>\n      <td>2.215</td>\n      <td>NaN</td>\n      <td>NBA006</td>\n      <td>15.5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>47</td>\n      <td>3</td>\n      <td>23</td>\n      <td>115</td>\n      <td>0.653</td>\n      <td>3.947</td>\n      <td>0.0</td>\n      <td>NBA011</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>44</td>\n      <td>3</td>\n      <td>8</td>\n      <td>88</td>\n      <td>0.285</td>\n      <td>5.083</td>\n      <td>1.0</td>\n      <td>NBA010</td>\n      <td>6.1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>34</td>\n      <td>2</td>\n      <td>9</td>\n      <td>40</td>\n      <td>0.374</td>\n      <td>0.266</td>\n      <td>NaN</td>\n      <td>NBA003</td>\n      <td>1.6</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>24</td>\n      <td>1</td>\n      <td>7</td>\n      <td>18</td>\n      <td>0.526</td>\n      <td>0.643</td>\n      <td>0.0</td>\n      <td>NBA000</td>\n      <td>6.5</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>46</td>\n      <td>1</td>\n      <td>6</td>\n      <td>30</td>\n      <td>1.415</td>\n      <td>3.865</td>\n      <td>NaN</td>\n      <td>NBA019</td>\n      <td>17.6</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>28</td>\n      <td>3</td>\n      <td>2</td>\n      <td>20</td>\n      <td>0.233</td>\n      <td>1.647</td>\n      <td>1.0</td>\n      <td>NBA000</td>\n      <td>9.4</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>24</td>\n      <td>1</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0.185</td>\n      <td>1.287</td>\n      <td>NaN</td>\n      <td>NBA005</td>\n      <td>9.2</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>29</td>\n      <td>1</td>\n      <td>1</td>\n      <td>17</td>\n      <td>0.132</td>\n      <td>0.293</td>\n      <td>0.0</td>\n      <td>NBA004</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>43</td>\n      <td>4</td>\n      <td>1</td>\n      <td>26</td>\n      <td>1.519</td>\n      <td>1.237</td>\n      <td>0.0</td>\n      <td>NBA005</td>\n      <td>10.6</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>44</td>\n      <td>1</td>\n      <td>18</td>\n      <td>61</td>\n      <td>2.806</td>\n      <td>3.782</td>\n      <td>NaN</td>\n      <td>NBA000</td>\n      <td>10.8</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>36</td>\n      <td>1</td>\n      <td>16</td>\n      <td>32</td>\n      <td>0.544</td>\n      <td>2.944</td>\n      <td>NaN</td>\n      <td>NBA013</td>\n      <td>10.9</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>29</td>\n      <td>2</td>\n      <td>6</td>\n      <td>25</td>\n      <td>0.585</td>\n      <td>0.465</td>\n      <td>0.0</td>\n      <td>NBA009</td>\n      <td>4.2</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>36</td>\n      <td>3</td>\n      <td>10</td>\n      <td>43</td>\n      <td>0.961</td>\n      <td>4.629</td>\n      <td>0.0</td>\n      <td>NBA004</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>28</td>\n      <td>3</td>\n      <td>6</td>\n      <td>47</td>\n      <td>5.574</td>\n      <td>3.732</td>\n      <td>1.0</td>\n      <td>NBA008</td>\n      <td>19.8</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>45</td>\n      <td>1</td>\n      <td>19</td>\n      <td>77</td>\n      <td>2.303</td>\n      <td>4.165</td>\n      <td>0.0</td>\n      <td>NBA022</td>\n      <td>8.4</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>37</td>\n      <td>4</td>\n      <td>10</td>\n      <td>123</td>\n      <td>3.022</td>\n      <td>18.257</td>\n      <td>0.0</td>\n      <td>NBA018</td>\n      <td>17.3</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>43</td>\n      <td>1</td>\n      <td>9</td>\n      <td>66</td>\n      <td>2.341</td>\n      <td>3.467</td>\n      <td>NaN</td>\n      <td>NBA008</td>\n      <td>8.8</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>24</td>\n      <td>1</td>\n      <td>4</td>\n      <td>21</td>\n      <td>0.099</td>\n      <td>0.447</td>\n      <td>0.0</td>\n      <td>NBA002</td>\n      <td>2.6</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>37</td>\n      <td>1</td>\n      <td>19</td>\n      <td>38</td>\n      <td>2.591</td>\n      <td>2.539</td>\n      <td>NaN</td>\n      <td>NBA007</td>\n      <td>13.5</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>38</td>\n      <td>2</td>\n      <td>13</td>\n      <td>59</td>\n      <td>0.408</td>\n      <td>1.008</td>\n      <td>0.0</td>\n      <td>NBA000</td>\n      <td>2.4</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>30</td>\n      <td>34</td>\n      <td>2</td>\n      <td>9</td>\n      <td>45</td>\n      <td>1.118</td>\n      <td>3.427</td>\n      <td>0.0</td>\n      <td>NBA013</td>\n      <td>10.1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>820</th>\n      <td>821</td>\n      <td>37</td>\n      <td>1</td>\n      <td>4</td>\n      <td>24</td>\n      <td>0.419</td>\n      <td>2.989</td>\n      <td>NaN</td>\n      <td>NBA010</td>\n      <td>14.2</td>\n    </tr>\n    <tr>\n      <th>821</th>\n      <td>822</td>\n      <td>32</td>\n      <td>1</td>\n      <td>16</td>\n      <td>38</td>\n      <td>0.694</td>\n      <td>7.286</td>\n      <td>0.0</td>\n      <td>NBA010</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>822</th>\n      <td>823</td>\n      <td>45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>20</td>\n      <td>0.105</td>\n      <td>0.315</td>\n      <td>0.0</td>\n      <td>NBA015</td>\n      <td>2.1</td>\n    </tr>\n    <tr>\n      <th>823</th>\n      <td>824</td>\n      <td>27</td>\n      <td>4</td>\n      <td>0</td>\n      <td>25</td>\n      <td>1.419</td>\n      <td>1.756</td>\n      <td>1.0</td>\n      <td>NBA000</td>\n      <td>12.7</td>\n    </tr>\n    <tr>\n      <th>824</th>\n      <td>825</td>\n      <td>41</td>\n      <td>2</td>\n      <td>4</td>\n      <td>26</td>\n      <td>1.473</td>\n      <td>3.519</td>\n      <td>1.0</td>\n      <td>NBA014</td>\n      <td>19.2</td>\n    </tr>\n    <tr>\n      <th>825</th>\n      <td>826</td>\n      <td>32</td>\n      <td>2</td>\n      <td>12</td>\n      <td>116</td>\n      <td>4.027</td>\n      <td>2.585</td>\n      <td>NaN</td>\n      <td>NBA011</td>\n      <td>5.7</td>\n    </tr>\n    <tr>\n      <th>826</th>\n      <td>827</td>\n      <td>48</td>\n      <td>1</td>\n      <td>13</td>\n      <td>50</td>\n      <td>6.114</td>\n      <td>9.286</td>\n      <td>1.0</td>\n      <td>NBA020</td>\n      <td>30.8</td>\n    </tr>\n    <tr>\n      <th>827</th>\n      <td>828</td>\n      <td>50</td>\n      <td>1</td>\n      <td>1</td>\n      <td>26</td>\n      <td>1.852</td>\n      <td>1.866</td>\n      <td>0.0</td>\n      <td>NBA026</td>\n      <td>14.3</td>\n    </tr>\n    <tr>\n      <th>828</th>\n      <td>829</td>\n      <td>45</td>\n      <td>3</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0.030</td>\n      <td>0.894</td>\n      <td>0.0</td>\n      <td>NBA019</td>\n      <td>4.2</td>\n    </tr>\n    <tr>\n      <th>829</th>\n      <td>830</td>\n      <td>33</td>\n      <td>2</td>\n      <td>2</td>\n      <td>37</td>\n      <td>0.834</td>\n      <td>0.831</td>\n      <td>0.0</td>\n      <td>NBA009</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>830</th>\n      <td>831</td>\n      <td>33</td>\n      <td>1</td>\n      <td>13</td>\n      <td>52</td>\n      <td>2.714</td>\n      <td>8.362</td>\n      <td>1.0</td>\n      <td>NBA003</td>\n      <td>21.3</td>\n    </tr>\n    <tr>\n      <th>831</th>\n      <td>832</td>\n      <td>27</td>\n      <td>2</td>\n      <td>8</td>\n      <td>18</td>\n      <td>0.401</td>\n      <td>1.741</td>\n      <td>0.0</td>\n      <td>NBA007</td>\n      <td>11.9</td>\n    </tr>\n    <tr>\n      <th>832</th>\n      <td>833</td>\n      <td>36</td>\n      <td>2</td>\n      <td>7</td>\n      <td>43</td>\n      <td>2.649</td>\n      <td>3.973</td>\n      <td>0.0</td>\n      <td>NBA016</td>\n      <td>15.4</td>\n    </tr>\n    <tr>\n      <th>833</th>\n      <td>834</td>\n      <td>30</td>\n      <td>4</td>\n      <td>7</td>\n      <td>30</td>\n      <td>0.264</td>\n      <td>4.446</td>\n      <td>0.0</td>\n      <td>NBA010</td>\n      <td>15.7</td>\n    </tr>\n    <tr>\n      <th>834</th>\n      <td>835</td>\n      <td>28</td>\n      <td>2</td>\n      <td>3</td>\n      <td>36</td>\n      <td>0.384</td>\n      <td>2.712</td>\n      <td>0.0</td>\n      <td>NBA001</td>\n      <td>8.6</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>836</td>\n      <td>21</td>\n      <td>3</td>\n      <td>0</td>\n      <td>41</td>\n      <td>2.367</td>\n      <td>5.628</td>\n      <td>NaN</td>\n      <td>NBA001</td>\n      <td>19.5</td>\n    </tr>\n    <tr>\n      <th>836</th>\n      <td>837</td>\n      <td>23</td>\n      <td>2</td>\n      <td>3</td>\n      <td>24</td>\n      <td>0.552</td>\n      <td>0.960</td>\n      <td>0.0</td>\n      <td>NBA004</td>\n      <td>6.3</td>\n    </tr>\n    <tr>\n      <th>837</th>\n      <td>838</td>\n      <td>23</td>\n      <td>1</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.849</td>\n      <td>2.319</td>\n      <td>0.0</td>\n      <td>NBA003</td>\n      <td>14.4</td>\n    </tr>\n    <tr>\n      <th>838</th>\n      <td>839</td>\n      <td>26</td>\n      <td>1</td>\n      <td>10</td>\n      <td>25</td>\n      <td>1.306</td>\n      <td>0.469</td>\n      <td>0.0</td>\n      <td>NBA001</td>\n      <td>7.1</td>\n    </tr>\n    <tr>\n      <th>839</th>\n      <td>840</td>\n      <td>31</td>\n      <td>1</td>\n      <td>8</td>\n      <td>22</td>\n      <td>0.370</td>\n      <td>1.104</td>\n      <td>0.0</td>\n      <td>NBA001</td>\n      <td>6.7</td>\n    </tr>\n    <tr>\n      <th>840</th>\n      <td>841</td>\n      <td>38</td>\n      <td>3</td>\n      <td>13</td>\n      <td>25</td>\n      <td>0.343</td>\n      <td>1.082</td>\n      <td>0.0</td>\n      <td>NBA018</td>\n      <td>5.7</td>\n    </tr>\n    <tr>\n      <th>841</th>\n      <td>842</td>\n      <td>29</td>\n      <td>3</td>\n      <td>7</td>\n      <td>63</td>\n      <td>0.572</td>\n      <td>2.893</td>\n      <td>0.0</td>\n      <td>NBA001</td>\n      <td>5.5</td>\n    </tr>\n    <tr>\n      <th>842</th>\n      <td>843</td>\n      <td>32</td>\n      <td>1</td>\n      <td>14</td>\n      <td>36</td>\n      <td>0.273</td>\n      <td>0.591</td>\n      <td>0.0</td>\n      <td>NBA000</td>\n      <td>2.4</td>\n    </tr>\n    <tr>\n      <th>843</th>\n      <td>844</td>\n      <td>32</td>\n      <td>2</td>\n      <td>8</td>\n      <td>45</td>\n      <td>0.982</td>\n      <td>0.683</td>\n      <td>0.0</td>\n      <td>NBA002</td>\n      <td>3.7</td>\n    </tr>\n    <tr>\n      <th>844</th>\n      <td>845</td>\n      <td>41</td>\n      <td>1</td>\n      <td>7</td>\n      <td>43</td>\n      <td>0.694</td>\n      <td>1.198</td>\n      <td>0.0</td>\n      <td>NBA011</td>\n      <td>4.4</td>\n    </tr>\n    <tr>\n      <th>845</th>\n      <td>846</td>\n      <td>27</td>\n      <td>1</td>\n      <td>5</td>\n      <td>26</td>\n      <td>0.548</td>\n      <td>1.220</td>\n      <td>NaN</td>\n      <td>NBA007</td>\n      <td>6.8</td>\n    </tr>\n    <tr>\n      <th>846</th>\n      <td>847</td>\n      <td>28</td>\n      <td>2</td>\n      <td>7</td>\n      <td>34</td>\n      <td>0.359</td>\n      <td>2.021</td>\n      <td>0.0</td>\n      <td>NBA002</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>847</th>\n      <td>848</td>\n      <td>25</td>\n      <td>4</td>\n      <td>0</td>\n      <td>18</td>\n      <td>2.802</td>\n      <td>3.210</td>\n      <td>1.0</td>\n      <td>NBA001</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>848</th>\n      <td>849</td>\n      <td>32</td>\n      <td>1</td>\n      <td>12</td>\n      <td>28</td>\n      <td>0.116</td>\n      <td>0.696</td>\n      <td>0.0</td>\n      <td>NBA012</td>\n      <td>2.9</td>\n    </tr>\n    <tr>\n      <th>849</th>\n      <td>850</td>\n      <td>52</td>\n      <td>1</td>\n      <td>16</td>\n      <td>64</td>\n      <td>1.866</td>\n      <td>3.638</td>\n      <td>0.0</td>\n      <td>NBA025</td>\n      <td>8.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>850 rows \u00d7 10 columns</p>\n</div>", 
                        "text/plain": "     Customer Id  Age  Edu  Years Employed  Income  Card Debt  Other Debt  \\\n0              1   41    2               6      19      0.124       1.073   \n1              2   47    1              26     100      4.582       8.218   \n2              3   33    2              10      57      6.111       5.802   \n3              4   29    2               4      19      0.681       0.516   \n4              5   47    1              31     253      9.308       8.908   \n5              6   40    1              23      81      0.998       7.831   \n6              7   38    2               4      56      0.442       0.454   \n7              8   42    3               0      64      0.279       3.945   \n8              9   26    1               5      18      0.575       2.215   \n9             10   47    3              23     115      0.653       3.947   \n10            11   44    3               8      88      0.285       5.083   \n11            12   34    2               9      40      0.374       0.266   \n12            13   24    1               7      18      0.526       0.643   \n13            14   46    1               6      30      1.415       3.865   \n14            15   28    3               2      20      0.233       1.647   \n15            16   24    1               1      16      0.185       1.287   \n16            17   29    1               1      17      0.132       0.293   \n17            18   43    4               1      26      1.519       1.237   \n18            19   44    1              18      61      2.806       3.782   \n19            20   36    1              16      32      0.544       2.944   \n20            21   29    2               6      25      0.585       0.465   \n21            22   36    3              10      43      0.961       4.629   \n22            23   28    3               6      47      5.574       3.732   \n23            24   45    1              19      77      2.303       4.165   \n24            25   37    4              10     123      3.022      18.257   \n25            26   43    1               9      66      2.341       3.467   \n26            27   24    1               4      21      0.099       0.447   \n27            28   37    1              19      38      2.591       2.539   \n28            29   38    2              13      59      0.408       1.008   \n29            30   34    2               9      45      1.118       3.427   \n..           ...  ...  ...             ...     ...        ...         ...   \n820          821   37    1               4      24      0.419       2.989   \n821          822   32    1              16      38      0.694       7.286   \n822          823   45    1               3      20      0.105       0.315   \n823          824   27    4               0      25      1.419       1.756   \n824          825   41    2               4      26      1.473       3.519   \n825          826   32    2              12     116      4.027       2.585   \n826          827   48    1              13      50      6.114       9.286   \n827          828   50    1               1      26      1.852       1.866   \n828          829   45    3               0      22      0.030       0.894   \n829          830   33    2               2      37      0.834       0.831   \n830          831   33    1              13      52      2.714       8.362   \n831          832   27    2               8      18      0.401       1.741   \n832          833   36    2               7      43      2.649       3.973   \n833          834   30    4               7      30      0.264       4.446   \n834          835   28    2               3      36      0.384       2.712   \n835          836   21    3               0      41      2.367       5.628   \n836          837   23    2               3      24      0.552       0.960   \n837          838   23    1               7      22      0.849       2.319   \n838          839   26    1              10      25      1.306       0.469   \n839          840   31    1               8      22      0.370       1.104   \n840          841   38    3              13      25      0.343       1.082   \n841          842   29    3               7      63      0.572       2.893   \n842          843   32    1              14      36      0.273       0.591   \n843          844   32    2               8      45      0.982       0.683   \n844          845   41    1               7      43      0.694       1.198   \n845          846   27    1               5      26      0.548       1.220   \n846          847   28    2               7      34      0.359       2.021   \n847          848   25    4               0      18      2.802       3.210   \n848          849   32    1              12      28      0.116       0.696   \n849          850   52    1              16      64      1.866       3.638   \n\n     Defaulted Address  DebtIncomeRatio  \n0          0.0  NBA001              6.3  \n1          0.0  NBA021             12.8  \n2          1.0  NBA013             20.9  \n3          0.0  NBA009              6.3  \n4          0.0  NBA008              7.2  \n5          NaN  NBA016             10.9  \n6          0.0  NBA013              1.6  \n7          0.0  NBA009              6.6  \n8          NaN  NBA006             15.5  \n9          0.0  NBA011              4.0  \n10         1.0  NBA010              6.1  \n11         NaN  NBA003              1.6  \n12         0.0  NBA000              6.5  \n13         NaN  NBA019             17.6  \n14         1.0  NBA000              9.4  \n15         NaN  NBA005              9.2  \n16         0.0  NBA004              2.5  \n17         0.0  NBA005             10.6  \n18         NaN  NBA000             10.8  \n19         NaN  NBA013             10.9  \n20         0.0  NBA009              4.2  \n21         0.0  NBA004             13.0  \n22         1.0  NBA008             19.8  \n23         0.0  NBA022              8.4  \n24         0.0  NBA018             17.3  \n25         NaN  NBA008              8.8  \n26         0.0  NBA002              2.6  \n27         NaN  NBA007             13.5  \n28         0.0  NBA000              2.4  \n29         0.0  NBA013             10.1  \n..         ...     ...              ...  \n820        NaN  NBA010             14.2  \n821        0.0  NBA010             21.0  \n822        0.0  NBA015              2.1  \n823        1.0  NBA000             12.7  \n824        1.0  NBA014             19.2  \n825        NaN  NBA011              5.7  \n826        1.0  NBA020             30.8  \n827        0.0  NBA026             14.3  \n828        0.0  NBA019              4.2  \n829        0.0  NBA009              4.5  \n830        1.0  NBA003             21.3  \n831        0.0  NBA007             11.9  \n832        0.0  NBA016             15.4  \n833        0.0  NBA010             15.7  \n834        0.0  NBA001              8.6  \n835        NaN  NBA001             19.5  \n836        0.0  NBA004              6.3  \n837        0.0  NBA003             14.4  \n838        0.0  NBA001              7.1  \n839        0.0  NBA001              6.7  \n840        0.0  NBA018              5.7  \n841        0.0  NBA001              5.5  \n842        0.0  NBA000              2.4  \n843        0.0  NBA002              3.7  \n844        0.0  NBA011              4.4  \n845        NaN  NBA007              6.8  \n846        0.0  NBA002              7.0  \n847        1.0  NBA001             33.4  \n848        0.0  NBA012              2.9  \n849        0.0  NBA025              8.6  \n\n[850 rows x 10 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "Data"
        }, 
        {
            "execution_count": 74, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 74, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer Id</th>\n      <th>Age</th>\n      <th>Edu</th>\n      <th>Years Employed</th>\n      <th>Income</th>\n      <th>Card Debt</th>\n      <th>Other Debt</th>\n      <th>Defaulted</th>\n      <th>DebtIncomeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>41</td>\n      <td>2</td>\n      <td>6</td>\n      <td>19</td>\n      <td>0.124</td>\n      <td>1.073</td>\n      <td>0.0</td>\n      <td>6.3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>47</td>\n      <td>1</td>\n      <td>26</td>\n      <td>100</td>\n      <td>4.582</td>\n      <td>8.218</td>\n      <td>0.0</td>\n      <td>12.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>33</td>\n      <td>2</td>\n      <td>10</td>\n      <td>57</td>\n      <td>6.111</td>\n      <td>5.802</td>\n      <td>1.0</td>\n      <td>20.9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>29</td>\n      <td>2</td>\n      <td>4</td>\n      <td>19</td>\n      <td>0.681</td>\n      <td>0.516</td>\n      <td>0.0</td>\n      <td>6.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>47</td>\n      <td>1</td>\n      <td>31</td>\n      <td>253</td>\n      <td>9.308</td>\n      <td>8.908</td>\n      <td>0.0</td>\n      <td>7.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   Customer Id  Age  Edu  Years Employed  Income  Card Debt  Other Debt  \\\n0            1   41    2               6      19      0.124       1.073   \n1            2   47    1              26     100      4.582       8.218   \n2            3   33    2              10      57      6.111       5.802   \n3            4   29    2               4      19      0.681       0.516   \n4            5   47    1              31     253      9.308       8.908   \n\n   Defaulted  DebtIncomeRatio  \n0        0.0              6.3  \n1        0.0             12.8  \n2        1.0             20.9  \n3        0.0              6.3  \n4        0.0              7.2  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#As you can see address is categorical variable so we will have to remove it\nData1 = Data.drop('Address', axis=1)\nData1.head()\n"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 13, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[ 41.   ,   2.   ,   6.   , ...,   0.124,   1.073,   6.3  ],\n       [ 47.   ,   1.   ,  26.   , ...,   4.582,   8.218,  12.8  ],\n       [ 33.   ,   2.   ,  10.   , ...,   6.111,   5.802,  20.9  ],\n       ..., \n       [ 25.   ,   4.   ,   0.   , ...,   2.802,   3.21 ,  33.4  ],\n       [ 32.   ,   1.   ,  12.   , ...,   0.116,   0.696,   2.9  ],\n       [ 52.   ,   1.   ,  16.   , ...,   1.866,   3.638,   8.6  ]])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "a = Data1[['Age','Edu','Years Employed','Income','Card Debt','Other Debt','DebtIncomeRatio']] .values  #.astype(float)\na"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 14, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([  0.,   0.,   1.,   0.,   0.,  nan,   0.,   0.,  nan,   0.])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "y = Data1['Defaulted'].values\ny[0:10]\n\n"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 15, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# As you ca see there are some Nans present in the defaulted column in the data set so we need to convert it to a numerical value \nimport numpy as np\ny = np.nan_to_num(y)\ny[0:10]"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 16, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[ 0.74291541,  0.31212243, -0.37878978, ..., -0.68381116,\n        -0.59048916, -0.57652509],\n       [ 1.48949049, -0.76634938,  2.5737211 , ...,  1.41447366,\n         1.51296181,  0.39138677],\n       [-0.25251804,  0.31212243,  0.2117124 , ...,  2.13414111,\n         0.80170393,  1.59755385],\n       ..., \n       [-1.24795149,  2.46906604, -1.26454304, ...,  0.5766659 ,\n         0.03863257,  3.45892281],\n       [-0.37694723, -0.76634938,  0.50696349, ..., -0.68757659,\n        -0.70147601, -1.08281745],\n       [ 2.1116364 , -0.76634938,  1.09746566, ...,  0.13611081,\n         0.16463355, -0.2340332 ]])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Since we are using the different classification models so it is bettrer to normalizing the data set-\nfrom sklearn.preprocessing import StandardScaler\na = np.nan_to_num(a)\nx = StandardScaler().fit_transform(a)"
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 17, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.0    517\n1.0    183\nName: Defaulted, dtype: int64"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "Data1['Defaulted'].value_counts()"
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train set: (680, 7) (680,)\nTest set: (170, 7) (170,)\n"
                }
            ], 
            "source": "#Train and Test Split-\n#We will train our model on the 80% of the data and test it on the rest 20% \nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=4)\nprint ('Train set:', x_train.shape,  y_train.shape)\nprint ('Test set:', x_test.shape,  y_test.shape)"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 22, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# KNN-\nfrom sklearn.neighbors import KNeighborsClassifier\n# Lets take k=5\nk=5\nknn = KNeighborsClassifier(n_neighbors = k).fit(x_train,y_train) \nknn"
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 25, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([ 0.,  0.,  0.,  0.,  1.])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "yhat = knn.predict(x_test)\nyhat[0:5]"
        }, 
        {
            "execution_count": 109, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train set Accuracy:  0.833823529412\nTest set Accuracy:  0.811764705882\n"
                }
            ], 
            "source": "#Accuracy evaluation\n#jaccard_similarity_score function\nfrom sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, knn.predict(x_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))"
        }, 
        {
            "execution_count": 40, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 40, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([ 0.75294118,  0.81176471,  0.79411765,  0.81176471,  0.82352941,\n        0.82941176,  0.82352941,  0.81764706,  0.81176471])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# We can calculate accuracy for different values of K\nks = 10\nmean_acc = np.zeros((ks-1))\nstd_acc = np.zeros((ks-1))\nConfustionMx = [];\nfor n in range(1,ks):\n    \n    #Train Model and Predict  \n    knn = KNeighborsClassifier(n_neighbors = n).fit(x_train,y_train)\n    yhat=knn.predict(x_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n\nmean_acc"
        }, 
        {
            "execution_count": 41, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fd94b0635f8>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "#Ploting model accuracy with different value of K\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nplt.plot(range(1,ks),mean_acc,'g')\nplt.fill_between(range(1,ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()"
        }, 
        {
            "execution_count": 42, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "The best accuracy was with 0.829411764706 with k= 6\n"
                }
            ], 
            "source": "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) "
        }, 
        {
            "execution_count": 98, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 98, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#Decision Trees_\nfrom sklearn.tree import DecisionTreeClassifier\nDT = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nDT\n"
        }, 
        {
            "execution_count": 99, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 99, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "DT.fit(x_train,y_train)\nDT"
        }, 
        {
            "execution_count": 102, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 102, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([ 0.,  0.,  0.,  0.,  0.])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "yhat_DT = DT.predict(x_test)\nyhat_DT[0:5]"
        }, 
        {
            "execution_count": 103, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 103, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([ 0.,  0.,  0.,  0.,  0.])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "y_test[0:5]"
        }, 
        {
            "execution_count": 88, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "DecisionTrees's Accuracy:  0.788235294118\n"
                }
            ], 
            "source": "#Accuracy Evaluation\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test,yhat_DT))"
        }, 
        {
            "execution_count": 96, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# With maximum depth=4 the accuracy is 0.788235294118"
        }, 
        {
            "execution_count": 97, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Logistic Regression-\n"
        }, 
        {
            "execution_count": 153, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 153, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLR = LogisticRegression(C=0.1, solver='liblinear').fit(x_train,y_train)\nLR\n#liblinear is numerical optimizer to find the parameters.\n#C parameter indicates inverse of regularization strength. Regularization is a technique used to solve the overfitting problem. Smaller values of C specify stronger regularization."
        }, 
        {
            "execution_count": 105, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 105, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "yhat_LR = LR.predict(x_test)\nyhat_LR"
        }, 
        {
            "execution_count": 154, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 154, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[ 0.83,  0.17],\n       [ 0.93,  0.07],\n       [ 0.85,  0.15],\n       [ 0.87,  0.13],\n       [ 0.27,  0.73],\n       [ 0.56,  0.44],\n       [ 0.94,  0.06],\n       [ 0.44,  0.56],\n       [ 0.61,  0.39],\n       [ 0.87,  0.13],\n       [ 0.86,  0.14],\n       [ 0.8 ,  0.2 ],\n       [ 0.71,  0.29],\n       [ 0.77,  0.23],\n       [ 0.53,  0.47],\n       [ 0.63,  0.37],\n       [ 0.95,  0.05],\n       [ 0.93,  0.07],\n       [ 0.84,  0.16],\n       [ 0.66,  0.34],\n       [ 0.81,  0.19],\n       [ 0.65,  0.35],\n       [ 0.84,  0.16],\n       [ 0.86,  0.14],\n       [ 0.94,  0.06],\n       [ 0.65,  0.35],\n       [ 0.76,  0.24],\n       [ 0.74,  0.26],\n       [ 0.71,  0.29],\n       [ 0.6 ,  0.4 ],\n       [ 0.87,  0.13],\n       [ 0.75,  0.25],\n       [ 0.81,  0.19],\n       [ 0.62,  0.38],\n       [ 0.93,  0.07],\n       [ 0.92,  0.08],\n       [ 0.93,  0.07],\n       [ 0.69,  0.31],\n       [ 0.76,  0.24],\n       [ 0.84,  0.16],\n       [ 0.21,  0.79],\n       [ 0.8 ,  0.2 ],\n       [ 0.86,  0.14],\n       [ 0.64,  0.36],\n       [ 0.81,  0.19],\n       [ 0.77,  0.23],\n       [ 0.71,  0.29],\n       [ 0.92,  0.08],\n       [ 0.36,  0.64],\n       [ 0.77,  0.23],\n       [ 0.93,  0.07],\n       [ 0.96,  0.04],\n       [ 0.74,  0.26],\n       [ 0.87,  0.13],\n       [ 0.92,  0.08],\n       [ 0.73,  0.27],\n       [ 0.71,  0.29],\n       [ 0.47,  0.53],\n       [ 0.31,  0.69],\n       [ 0.97,  0.03],\n       [ 0.96,  0.04],\n       [ 0.92,  0.08],\n       [ 0.96,  0.04],\n       [ 0.63,  0.37],\n       [ 0.88,  0.12],\n       [ 0.76,  0.24],\n       [ 0.74,  0.26],\n       [ 0.94,  0.06],\n       [ 0.42,  0.58],\n       [ 0.55,  0.45],\n       [ 0.86,  0.14],\n       [ 0.98,  0.02],\n       [ 0.98,  0.02],\n       [ 0.86,  0.14],\n       [ 0.65,  0.35],\n       [ 0.75,  0.25],\n       [ 0.75,  0.25],\n       [ 0.9 ,  0.1 ],\n       [ 0.92,  0.08],\n       [ 0.88,  0.12],\n       [ 0.63,  0.37],\n       [ 0.57,  0.43],\n       [ 0.55,  0.45],\n       [ 0.15,  0.85],\n       [ 0.86,  0.14],\n       [ 0.92,  0.08],\n       [ 0.53,  0.47],\n       [ 0.83,  0.17],\n       [ 0.37,  0.63],\n       [ 0.95,  0.05],\n       [ 0.65,  0.35],\n       [ 0.73,  0.27],\n       [ 0.65,  0.35],\n       [ 0.77,  0.23],\n       [ 0.34,  0.66],\n       [ 0.69,  0.31],\n       [ 0.81,  0.19],\n       [ 0.51,  0.49],\n       [ 0.76,  0.24],\n       [ 0.85,  0.15],\n       [ 0.8 ,  0.2 ],\n       [ 0.94,  0.06],\n       [ 0.81,  0.19],\n       [ 0.79,  0.21],\n       [ 0.81,  0.19],\n       [ 0.72,  0.28],\n       [ 0.82,  0.18],\n       [ 0.36,  0.64],\n       [ 0.89,  0.11],\n       [ 0.71,  0.29],\n       [ 0.87,  0.13],\n       [ 0.84,  0.16],\n       [ 0.86,  0.14],\n       [ 0.73,  0.27],\n       [ 0.93,  0.07],\n       [ 0.91,  0.09],\n       [ 0.82,  0.18],\n       [ 0.83,  0.17],\n       [ 0.49,  0.51],\n       [ 0.63,  0.37],\n       [ 0.96,  0.04],\n       [ 0.67,  0.33],\n       [ 0.86,  0.14],\n       [ 0.83,  0.17],\n       [ 0.9 ,  0.1 ],\n       [ 0.95,  0.05],\n       [ 0.78,  0.22],\n       [ 0.88,  0.12],\n       [ 0.84,  0.16],\n       [ 0.49,  0.51],\n       [ 0.95,  0.05],\n       [ 0.89,  0.11],\n       [ 0.97,  0.03],\n       [ 0.56,  0.44],\n       [ 0.89,  0.11],\n       [ 0.51,  0.49],\n       [ 0.87,  0.13],\n       [ 0.7 ,  0.3 ],\n       [ 0.7 ,  0.3 ],\n       [ 0.8 ,  0.2 ],\n       [ 0.78,  0.22],\n       [ 0.61,  0.39],\n       [ 0.35,  0.65],\n       [ 0.9 ,  0.1 ],\n       [ 0.55,  0.45],\n       [ 0.69,  0.31],\n       [ 0.88,  0.12],\n       [ 0.49,  0.51],\n       [ 0.33,  0.67],\n       [ 0.82,  0.18],\n       [ 0.87,  0.13],\n       [ 0.46,  0.54],\n       [ 0.55,  0.45],\n       [ 0.81,  0.19],\n       [ 0.72,  0.28],\n       [ 0.79,  0.21],\n       [ 0.76,  0.24],\n       [ 0.65,  0.35],\n       [ 0.91,  0.09],\n       [ 0.47,  0.53],\n       [ 0.92,  0.08],\n       [ 0.98,  0.02],\n       [ 0.82,  0.18],\n       [ 0.54,  0.46],\n       [ 0.91,  0.09],\n       [ 0.97,  0.03],\n       [ 0.94,  0.06],\n       [ 0.73,  0.27],\n       [ 0.65,  0.35],\n       [ 0.84,  0.16]])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "yhat_prob = LR.predict_proba(x_test)\nyhat_prob"
        }, 
        {
            "execution_count": 155, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#The first column is the probability of class 1, P(Y=1|X), and second column is probability of class 0, P(Y=0|X)"
        }, 
        {
            "execution_count": 156, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 156, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.8294117647058824"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#Jaccard Index\nfrom sklearn.metrics import jaccard_similarity_score\njaccard_similarity_score(y_test, yhat_LR)\n"
        }, 
        {
            "execution_count": 191, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[[  7  21]\n [  8 134]]\n"
                }
            ], 
            "source": "from sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nprint(confusion_matrix(y_test, yhat_LR, labels=[1,0]))"
        }, 
        {
            "execution_count": 192, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Confusion matrix, without normalization\n[[  7  21]\n [  8 134]]\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fd948cd6198>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat_LR, labels=[1,0])\nnp.set_printoptions(precision=2)\n\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['1','0'],normalize= False,  title='Confusion matrix')"
        }, 
        {
            "execution_count": 149, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "             precision    recall  f1-score   support\n\n        0.0       0.86      0.94      0.90       142\n        1.0       0.47      0.25      0.33        28\n\navg / total       0.80      0.83      0.81       170\n\n"
                }
            ], 
            "source": "# F1 Score\nfrom sklearn.metrics import classification_report\nprint (classification_report(y_test, yhat_LR))"
        }, 
        {
            "execution_count": 116, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Precision is a measure of the accuracy provided that a class label has been predicted. It is defined by: precision = TP / (TP + FP)#\n#Recall is true positive rate. It is defined as: Recall = TP / (TP + FN)\n#F1 score is the harmonic average of the precision and recall.\n#F1-score for both labels-> 0.79. But for label 1 f1 score is very less which is very much evident by the confusion matrix."
        }, 
        {
            "execution_count": 117, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 117, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.47663674763273339"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#Log Loss\nfrom sklearn.metrics import log_loss\nlog_loss(y_test, yhat_prob)"
        }, 
        {
            "execution_count": 165, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#We will perform the same analysis again by using different numerical optimizer to see whether we get lower value of log loss or not. For example 'newton-cg'.\nLR = LogisticRegression(C=0.1, solver='newton-cg').fit(x_train,y_train)\nLR\nfrom sklearn.metrics import jaccard_similarity_score\njaccard_similarity_score(y_test, yhat_LR)\nyhat_prob = LR.predict_proba(x_test)\nyhat_LR = LR.predict(x_test)"
        }, 
        {
            "execution_count": 166, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "             precision    recall  f1-score   support\n\n        0.0       0.86      0.94      0.90       142\n        1.0       0.47      0.25      0.33        28\n\navg / total       0.80      0.83      0.81       170\n\n"
                }
            ], 
            "source": "from sklearn.metrics import classification_report\nprint (classification_report(y_test, yhat_LR))"
        }, 
        {
            "execution_count": 167, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 167, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.39291713877698137"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#Log Loss\nfrom sklearn.metrics import log_loss\nlog_loss(y_test, yhat_prob)"
        }, 
        {
            "execution_count": 122, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# We get lower value of the log loss by using 'newton-cg' instead of 'liblinear' "
        }, 
        {
            "execution_count": 206, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Support Vector Machine-"
        }, 
        {
            "execution_count": 187, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 187, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from sklearn import svm\n#We are using linear kernal function\nSvm = svm.SVC(kernel='linear')\nSvm.fit(x_train, y_train) "
        }, 
        {
            "execution_count": 189, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 189, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([ 0.,  0.,  0.,  0.,  1.])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "yhat_svm = Svm.predict(x_test)\nyhat_svm [0:5]"
        }, 
        {
            "execution_count": 190, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Accuracy Evaluation\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')"
        }, 
        {
            "execution_count": 193, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "             precision    recall  f1-score   support\n\n        0.0       0.85      0.94      0.89       142\n        1.0       0.36      0.18      0.24        28\n\navg / total       0.77      0.81      0.78       170\n\nConfusion matrix, without normalization\n[[133   9]\n [ 23   5]]\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fd948cdb630>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat_svm, labels=[0,1])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, yhat_svm))\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['1','0'],normalize= False,  title='Confusion matrix')"
        }, 
        {
            "execution_count": 194, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 194, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.78481379128832729"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#F1 Score->\nf1_score(y_test, yhat_svm, average='weighted') "
        }, 
        {
            "execution_count": 201, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 201, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.81176470588235294"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#Jaccard Index->\njaccard_similarity_score(y_test, yhat_svm)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}